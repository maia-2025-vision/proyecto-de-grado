{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T15:41:42.477041Z",
     "start_time": "2025-11-21T15:41:42.473040Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "import animaloc_improved.tools.infer_metrics as im\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    os.chdir(\"../\")\n",
    "    sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9911f097a56254d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T13:59:15.580737Z",
     "start_time": "2025-11-21T13:59:15.577593Z"
    }
   },
   "outputs": [],
   "source": [
    "SPECIES_MAP = {\n",
    "    1: \"Alcelaphinae\",\n",
    "    2: \"Buffalo\",\n",
    "    3: \"Kob\",\n",
    "    4: \"Warthog\",\n",
    "    5: \"Waterbuck\",\n",
    "    6: \"Elephant\",\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    \"ground_truth\": \"green\",\n",
    "    \"predictions\": \"red\",\n",
    "    \"correct\": \"blue\",\n",
    "    \"missed\": \"orange\",\n",
    "    \"false_positive\": \"purple\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c0b7128a2853859",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T14:18:52.685238Z",
     "start_time": "2025-11-21T14:18:52.676130Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_single_image_gt(gt_df: pd.DataFrame, image_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Extract ground truth data for a specific image.\"\"\"\n",
    "    image_data = gt_df[gt_df[\"images\"] == image_name].copy()\n",
    "\n",
    "    if image_data.empty:\n",
    "        raise ValueError(f\"No data found for image: {image_name}\")\n",
    "\n",
    "    print(f\"Found {len(image_data)} ground truth annotations for {image_name}\")\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92a493d295ed5965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:05:40.677749Z",
     "start_time": "2025-11-21T17:05:40.295475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: data/models/herdnet_v2_hn2/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"data/models/herdnet_v2_hn2/best_model.pth\"\n",
    "# MODEL_PATH = \"data/models/herdnet_v2/latest_model.pth\"\n",
    "# gt [points]\n",
    "GT_PATH = \"data/gt-preprocessed/csv/test_big_size_A_B_E_K_WH_WB-points.csv\"\n",
    "IMAGE_ROOT = Path(\"data/test\")\n",
    "# DEVICE = \"mps\"\n",
    "DEVICE = \"mps\"\n",
    "THRESHOLD = 15\n",
    "# gt [bboxes]\n",
    "# GT_PATH = \"data/groundtruth/csv/test_big_size_A_B_E_K_WH_WB-fixed-header.csv\"\n",
    "\n",
    "model = im.load_trained_model(MODEL_PATH)\n",
    "gt_pt_df = pd.read_csv(GT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8df5cca6321b1f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:05:45.152618Z",
     "start_time": "2025-11-21T17:05:45.139416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 ground truth annotations for 018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# IMAGE = \"01802f75da35434ab373569fffc1fd65a3417aef.JPG\"\n",
    "IMAGE = \"018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG\"\n",
    "\n",
    "image_path = IMAGE_ROOT / IMAGE\n",
    "ground_truth = get_single_image_gt(gt_pt_df, IMAGE)\n",
    "lmds_kwargs = {\"kernel_size\": [3, 3], \"adapt_ts\": 0.3}  # mismos params de la configuraci√≥n de test\n",
    "\n",
    "reload(im)\n",
    "# evaluator = im.make_evaluator( model=model, device_name=DEVICE, lmds_kwargs=lmds_kwargs )\n",
    "\n",
    "\n",
    "def eval_image_v2(model: nn.Module, ground_truth: pd.DataFrame, image_path: Path, threshold: float):\n",
    "    # image_path = os.path.join(image_root, image_name)\n",
    "    # print(ground_truth[['images', 'x', 'y', 'labels']].to_markdown())\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    # ground_truth = get_single_image_gt(gt_, image_name)\n",
    "\n",
    "    # Make predictions\n",
    "    prediction_results = im.predict_single_image_v2(\n",
    "        model=model,\n",
    "        image_path=image_path,\n",
    "        lmds_kwargs=lmds_kwargs,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    predictions = prediction_results[\"detections\"].sort_values(\"x\")\n",
    "    print(f\"{len(predictions)=}\")\n",
    "    # print(predictions[['images', 'x', 'y', 'labels']].to_markdown())\n",
    "\n",
    "    # Match predictions to ground truth\n",
    "    matches = im.match_predictions_to_gt(predictions, ground_truth, threshold)\n",
    "\n",
    "    # create_visualization(image_path, ground_truth, predictions, matches, COLORS, SPECIES_MAP)\n",
    "\n",
    "    im.print_evaluation_results(matches, ground_truth, predictions, SPECIES_MAP)\n",
    "\n",
    "    # print(\"\\nGround Truth Data:\")\n",
    "    # print(ground_truth.to_string())\n",
    "\n",
    "    # print(\"\\nPredictions:\")\n",
    "    # print(predictions.to_string())\n",
    "\n",
    "    return {\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"prediction_results\": prediction_results,\n",
    "        \"predictions\": predictions,\n",
    "        \"matches\": matches,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "efb56b75c2fcffce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:05:55.091192Z",
     "start_time": "2025-11-21T17:05:46.968608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for: 018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrestrepo/git/_personal/proyecto-de-grado/.venv/lib/python3.13/site-packages/albumentations/core/composition.py:331: UserWarning: Got processor for keypoints, but no transform to process it.\n",
      "  self._set_keys()\n",
      "\u001b[32m2025-11-21 12:05:51.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36manimaloc.eval.lmds\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m191\u001b[0m - \u001b[1mheatmap=torch.Size([1, 1, 3648, 5472]) cls_scores=torch.Size([1, 6, 3648, 5472])\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1/1] eta: 0:00:07  time: 7.2855 data: 0.3029\n",
      " Total time: 0:00:07 (7.2877 s / it)\n",
      "Found 11 predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrestrepo/git/_personal/proyecto-de-grado/.venv/lib/python3.13/site-packages/animaloc/eval/metrics.py:315: RuntimeWarning: invalid value encountered in divide\n",
      "  recalls = sorted_table[:,2] / n_gt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(predictions)=11\n",
      "\n",
      "============================================================\n",
      "EVALUATION RESULTS\n",
      "============================================================\n",
      "Ground Truth Points: 11\n",
      "Predicted Points: 11\n",
      "True Positives: 5\n",
      "False Positives: 6\n",
      "False Negatives: 6\n",
      "Precision: 0.455\n",
      "Recall: 0.455\n",
      "F1-Score: 0.455\n",
      "\n",
      "PER-CLASS BREAKDOWN:\n",
      "----------------------------------------\n",
      "Elephant: GT=11, Pred=11, TP=5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "eval_results = eval_image_v2(\n",
    "    model=model,\n",
    "    image_path=image_path,\n",
    "    ground_truth=ground_truth,\n",
    "    threshold=THRESHOLD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d4b032875c779ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:06:04.187485Z",
     "start_time": "2025-11-21T17:06:04.182794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>936</td>\n",
       "      <td>1529</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1239</td>\n",
       "      <td>1896</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1289</td>\n",
       "      <td>1867</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1498</td>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1489</td>\n",
       "      <td>2037</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1864</td>\n",
       "      <td>1778</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1902</td>\n",
       "      <td>1800</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>2192</td>\n",
       "      <td>1756</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>2146</td>\n",
       "      <td>2027</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>2700</td>\n",
       "      <td>2395</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1405</td>\n",
       "      <td>1657</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            images     x     y  labels\n",
       "1620  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   936  1529       6\n",
       "1621  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1239  1896       6\n",
       "1622  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1289  1867       6\n",
       "1623  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1498  1997       6\n",
       "1624  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1489  2037       6\n",
       "1625  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1864  1778       6\n",
       "1626  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1902  1800       6\n",
       "1627  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  2192  1756       6\n",
       "1628  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  2146  2027       6\n",
       "1629  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  2700  2395       6\n",
       "1630  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1405  1657       6"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results[\"ground_truth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ac5c18db5e571b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:06:08.765353Z",
     "start_time": "2025-11-21T17:06:08.758349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>936.0</td>\n",
       "      <td>1529.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1286.0</td>\n",
       "      <td>1868.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1718.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1724.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1776.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>1782.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1788.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>2147.0</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>2150.0</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>1760.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          images       x       y  labels\n",
       "2   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   936.0  1529.0       6\n",
       "7   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1286.0  1868.0       6\n",
       "0   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1718.0   658.0       6\n",
       "1   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1724.0   662.0       6\n",
       "4   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1866.0  1776.0       6\n",
       "5   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1870.0  1782.0       6\n",
       "6   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1880.0  1788.0       6\n",
       "8   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  2147.0  2027.0       6\n",
       "9   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  2150.0  2029.0       6\n",
       "3   018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  2190.0  1760.0       6\n",
       "10  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  3991.0  2817.0       6"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results[\"predictions\"].sort_values(\"x\")[[\"images\", \"x\", \"y\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ad75a45ca73d908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:06:24.118035Z",
     "start_time": "2025-11-21T17:06:24.105850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>467.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>643.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>859.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>862.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>933.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>940.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            images       x       y  labels\n",
       "1494  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   467.0   764.0     6.0\n",
       "1498  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   643.0   934.0     6.0\n",
       "1492  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   859.0   329.0     6.0\n",
       "1493  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   862.0   331.0     6.0\n",
       "1496  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   933.0   888.0     6.0\n",
       "1497  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG   940.0   894.0     6.0\n",
       "1499  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1073.0  1013.0     6.0\n",
       "1500  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1075.0  1014.0     6.0\n",
       "1495  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1095.0   880.0     6.0\n",
       "1501  018f5ab5b7516a47ff2ac48a9fc08353b533c30f.JPG  1995.0  1408.0     6.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dets = pd.read_csv(\"data/test_results/herdnet_v2_hn2/detections.csv\")\n",
    "test_dets_img = test_dets[test_dets[\"images\"] == IMAGE]\n",
    "test_dets_img[[\"images\", \"x\", \"y\", \"labels\"]].sort_values(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06709f8cb6be6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
